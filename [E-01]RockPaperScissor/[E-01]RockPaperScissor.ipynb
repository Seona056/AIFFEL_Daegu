{"cells":[{"cell_type":"code","execution_count":null,"id":"e9ecbdab","metadata":{"id":"e9ecbdab"},"outputs":[],"source":["from PIL import Image\n","import glob\n","import numpy as np\n","import os\n","\n","\n","def load_data(img_path, number_of_data):  \n","    # 가위 : 0, 바위 : 1, 보 : 2\n","    # 내가 만든 train 이미지는 총 314개이다.\n","    \n","    img_size=28\n","    color=3\n","    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n","    \n","    imgs = np.zeros(number_of_data*img_size*img_size*color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n","    # 1-4. 딥러닝 네트워크 학습시키기에 나온 내용 (컬러 채널값(3)을 만드는 reshape를 실행해야한다.)\n","    # 스텝에서 첫 번째 레이어에 input_shape=(28,28,1)로 지정했던 것을 기억하시나요? \n","    # 그런데 print(x_train.shape) 을 해보면,(60000, 28, 28) 로 채널수에 대한 정보가 없습니다. \n","    # 따라서 (60000, 28, 28, 1) 로 만들어 주어야 합니다\n","    # 라고 적혀있네요. \n","    # mnist에서는 흑백이라서 1이었지만, 지금 이미지는 컬러이기 때문에 3\n","    # (314, 28, 28, 3) : 28*28 컬러사진 314장\n","    \n","    labels = np.zeros(number_of_data, dtype=np.int32)\n","    # np.zeros() : 0으로 초기화 된 shape 차원의 ndarray 배열 객체를 반환\n","    # dtype=np.int32 : ndarray에 담긴 데이터 티입을 정수형 숫자로 지정\n","    # https://rfriend.tistory.com/285 에서 참고함\n","\n","    idx=0\n","    \n","    for file in glob.iglob(img_path+'/scissor/*.jpg'):    \n","        # glob.iglob() :실제로 동시에 저장하지 않고 glob()과 같은 값을 산출하는 이터레이터(반복가능한 객체)를 반환\n","        # glob는 해당 디렉토리의 파일명을 리스트 형식으로 반환한다.\n","        # * 는 모든 파일을 지정\n","      \n","        img = np.array(Image.open(file),dtype=np.int32)\n","        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n","        labels[idx]=0   # 가위 : 0\n","        idx=idx+1\n","    # 가위 전체 파일을 for문으로 반복해서 열어서, 0 으로 분류  \n","    \n","     \n","\n","    for file in glob.iglob(img_path+'/rock/*.jpg'):\n","        img = np.array(Image.open(file),dtype=np.int32)\n","        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n","        labels[idx]=1   # 바위 : 1\n","        idx=idx+1  \n","    # 바위 전체 파일을 for문으로 반복해서 열어서, 0 으로 분류 \n","    \n","    for file in glob.iglob(img_path+'/paper/*.jpg'):\n","        img = np.array(Image.open(file),dtype=np.int32)\n","        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n","        labels[idx]=2   # 보 : 2\n","        idx=idx+1\n","     # 보 전체 파일을 for문으로 반복해서 열어서, 0 으로 분류 \n","        \n","    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\") \n","\n","    # idx가 0으로 시작해서 for문을 세 번 돌고나서 +1씩 쌓인 누적 숫자 = 이미지 파일의 갯수\n","                           \n","    return imgs, labels"]},{"cell_type":"code","execution_count":null,"id":"84966c96","metadata":{"id":"84966c96","outputId":"111ccc57-5293-468b-893a-e47060d74a05"},"outputs":[{"name":"stdout","output_type":"stream","text":["학습데이터(x_train)의 이미지 개수는 314 입니다.\n","x_train shape: (314, 28, 28, 3)\n","y_train shape: (314,)\n"]}],"source":["image_dir_path = os.getenv(\"HOME\")+'/aiffel/rock_scissor_paper/img/train' # train 데이터 폴더 전체 오픈\n","\n","(x_train, y_train)=load_data(image_dir_path,314)\n","\n","# 위에서 작성한 함수 load_data 함수에 넣어서 x_train은 imgs, y_train은 labels로 반환된다.\n","# imgs는 (314, 28, 28, 3)으로 reshape된 img 배열이다.\n","# labels -> 가위 : 0, 바위 : 1, 보 : 2\n","\n","x_train_norm = x_train/255.0   \n","# 입력은 0~1 사이의 값으로 정규화 (rgb값이 0~255기 때문에 255로 나눠준다.)\n","# x 데이터만 정규화한다. y는 하지 않음\n","\n","\n","print(\"x_train shape: {}\".format(x_train.shape))\n","print(\"y_train shape: {}\".format(y_train.shape))"]},{"cell_type":"code","execution_count":null,"id":"cd4f3065","metadata":{"id":"cd4f3065","outputId":"864afbdf-2739-401e-d297-4cbb4f54b29f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 26, 26, 64)        1792      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3200)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 16)                51216     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                170       \n","=================================================================\n","Total params: 127,034\n","Trainable params: 127,034\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","\n","# model을 직접 만들어 보세요.\n","# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n","# [[YOUR CODE]]\n","\n","# 이 값일 때, 평가 정확도가 가장 높게 나왔음\n","n_channel_1=64\n","n_channel_2=128\n","n_dense=16\n","\n","model=keras.models.Sequential()\n","model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n","model.add(keras.layers.MaxPool2D(2,2))\n","model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n","model.add(keras.layers.MaxPooling2D((2,2)))\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dense(n_dense, activation='relu'))\n","model.add(keras.layers.Dense(10, activation='softmax'))\n","\n","model.summary()\n","model.compile(optimizer='adam',\n","             loss='sparse_categorical_crossentropy',\n","             metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"b7b14da7","metadata":{"id":"b7b14da7","outputId":"c7eb89ba-e6f1-44fa-c02f-fca15802c13b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","7/7 [==============================] - 3s 54ms/step - loss: 2.0331 - accuracy: 0.0000e+00 - val_loss: 1.6898 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","7/7 [==============================] - 0s 7ms/step - loss: 1.4865 - accuracy: 0.3699 - val_loss: 1.4745 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","7/7 [==============================] - 0s 6ms/step - loss: 1.2656 - accuracy: 0.3699 - val_loss: 1.1475 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","7/7 [==============================] - 0s 6ms/step - loss: 1.0432 - accuracy: 0.4932 - val_loss: 1.2136 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.9464 - accuracy: 0.5845 - val_loss: 1.7125 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.8364 - accuracy: 0.7397 - val_loss: 1.4665 - val_accuracy: 0.0105\n","Epoch 7/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.7642 - accuracy: 0.7352 - val_loss: 1.6637 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.6521 - accuracy: 0.7900 - val_loss: 1.2651 - val_accuracy: 0.0421\n","Epoch 9/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.5856 - accuracy: 0.8174 - val_loss: 1.4884 - val_accuracy: 0.0316\n","Epoch 10/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7900 - val_loss: 1.4011 - val_accuracy: 0.0526\n","Epoch 11/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.5524 - accuracy: 0.7626 - val_loss: 1.4511 - val_accuracy: 0.0421\n","Epoch 12/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7078 - val_loss: 1.3415 - val_accuracy: 0.0421\n","Epoch 13/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7991 - val_loss: 0.8842 - val_accuracy: 0.5579\n","Epoch 14/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7260 - val_loss: 1.7949 - val_accuracy: 0.0316\n","Epoch 15/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7489 - val_loss: 2.3330 - val_accuracy: 0.0211\n","Epoch 16/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.8311 - val_loss: 1.5985 - val_accuracy: 0.0421\n","Epoch 17/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.8219 - val_loss: 0.8214 - val_accuracy: 0.5895\n","Epoch 18/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8174 - val_loss: 1.0733 - val_accuracy: 0.1263\n","Epoch 19/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8584 - val_loss: 1.3390 - val_accuracy: 0.0526\n","Epoch 20/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8311 - val_loss: 1.6670 - val_accuracy: 0.0421\n","Epoch 21/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8493 - val_loss: 2.3273 - val_accuracy: 0.0316\n","Epoch 22/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7808 - val_loss: 2.2318 - val_accuracy: 0.0421\n","Epoch 23/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7534 - val_loss: 1.7673 - val_accuracy: 0.0421\n","Epoch 24/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7443 - val_loss: 0.9979 - val_accuracy: 0.3368\n","Epoch 25/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.8493 - val_loss: 0.5077 - val_accuracy: 0.7579\n","Epoch 26/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8311 - val_loss: 1.3025 - val_accuracy: 0.0737\n","Epoch 27/30\n","7/7 [==============================] - 0s 7ms/step - loss: 0.3559 - accuracy: 0.8356 - val_loss: 1.6959 - val_accuracy: 0.0421\n","Epoch 28/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8584 - val_loss: 0.5984 - val_accuracy: 0.7053\n","Epoch 29/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.2889 - accuracy: 0.9178 - val_loss: 1.1699 - val_accuracy: 0.1053\n","Epoch 30/30\n","7/7 [==============================] - 0s 6ms/step - loss: 0.2822 - accuracy: 0.8995 - val_loss: 0.5866 - val_accuracy: 0.7053\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f1f90026be0>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(x_train_norm, y_train, epochs=30, validation_split=0.3)\n","# train 데이터를 학습시킨다.\n","# validation_split 옵션으로, train데이터의 30%를 validation 용으로 분류.\n","# 나머지 70%의 자료로 학습한 후, vaildation 데이터로 중간 평가 한다."]},{"cell_type":"code","execution_count":null,"id":"1e82be00","metadata":{"id":"1e82be00","outputId":"5d341292-1b0a-4bc4-d44b-3a28d344d4cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["학습데이터(x_train)의 이미지 개수는 334 입니다.\n","x_test shape: (334, 28, 28, 3)\n","y_test shape: (334,)\n"]}],"source":["# 슬기님이 주신 테스트 데이터\n","\n","image_test_dir_path = os.getenv(\"HOME\")+'/aiffel/rock_scissor_paper/img/test'\n","\n","(x_test, y_test)=load_data(image_test_dir_path, 334)\n","x_test_norm = x_test/255.0  \n","\n","print(\"x_test shape: {}\".format(x_test.shape))\n","print(\"y_test shape: {}\".format(y_test.shape))"]},{"cell_type":"code","execution_count":null,"id":"c62c0adf","metadata":{"id":"c62c0adf","outputId":"10d370ee-8282-444d-b87d-b1d518507625"},"outputs":[{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - 0s 6ms/step - loss: 15.7398 - accuracy: 0.5389\n"]},{"data":{"text/plain":["[15.739775657653809, 0.538922131061554]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# 모델 평가\n","model.evaluate(x_test_norm, y_test)"]},{"cell_type":"code","execution_count":null,"id":"d02aab5e","metadata":{"id":"d02aab5e","outputId":"1bdcd18d-d042-4d24-87a0-703fe797332d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[0.57647059 0.6        0.6       ]\n","  [0.57647059 0.6        0.6       ]\n","  [0.57647059 0.59215686 0.60392157]\n","  ...\n","  [0.36078431 0.38039216 0.39215686]\n","  [0.34509804 0.36470588 0.37647059]\n","  [0.34509804 0.35686275 0.37647059]]\n","\n"," [[0.62352941 0.64705882 0.64705882]\n","  [0.60784314 0.63137255 0.63137255]\n","  [0.59215686 0.60784314 0.61176471]\n","  ...\n","  [0.36862745 0.38823529 0.4       ]\n","  [0.35686275 0.37647059 0.38823529]\n","  [0.35294118 0.36470588 0.38431373]]\n","\n"," [[0.62745098 0.65098039 0.65098039]\n","  [0.63137255 0.65490196 0.65490196]\n","  [0.63921569 0.65490196 0.65882353]\n","  ...\n","  [0.37647059 0.39607843 0.40784314]\n","  [0.36862745 0.38431373 0.39607843]\n","  [0.36078431 0.37647059 0.38823529]]\n","\n"," ...\n","\n"," [[0.3372549  0.35686275 0.36862745]\n","  [0.90196078 0.93333333 0.94117647]\n","  [0.96078431 0.99215686 1.        ]\n","  ...\n","  [0.45882353 0.43921569 0.4627451 ]\n","  [0.14509804 0.1254902  0.15294118]\n","  [0.10588235 0.08627451 0.11372549]]\n","\n"," [[0.2745098  0.28627451 0.30588235]\n","  [0.71764706 0.7372549  0.75294118]\n","  [0.70588235 0.7254902  0.74117647]\n","  ...\n","  [0.45098039 0.42352941 0.45098039]\n","  [0.17254902 0.15294118 0.18039216]\n","  [0.15686275 0.1372549  0.16470588]]\n","\n"," [[0.         0.00392157 0.02352941]\n","  [0.2627451  0.26666667 0.28627451]\n","  [0.20784314 0.22745098 0.24313725]\n","  ...\n","  [0.34901961 0.32156863 0.34901961]\n","  [0.14509804 0.11764706 0.14901961]\n","  [0.16862745 0.14901961 0.17647059]]]\n"]}],"source":["print(x_test_norm[0])"]},{"cell_type":"code","execution_count":null,"id":"fe5b3c0c","metadata":{"id":"fe5b3c0c","outputId":"19699388-7f9d-4793-f401-a1e4b6a06c3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[0.52941176 0.50196078 0.52941176]\n","  [0.5254902  0.49803922 0.5254902 ]\n","  [0.51764706 0.49411765 0.50980392]\n","  ...\n","  [0.10588235 0.0627451  0.03921569]\n","  [0.10980392 0.07058824 0.03529412]\n","  [0.14117647 0.10196078 0.0627451 ]]\n","\n"," [[0.5372549  0.50980392 0.5372549 ]\n","  [0.53333333 0.50588235 0.53333333]\n","  [0.5254902  0.50196078 0.51764706]\n","  ...\n","  [0.11372549 0.07058824 0.04705882]\n","  [0.1254902  0.08627451 0.05098039]\n","  [0.17254902 0.13333333 0.09411765]]\n","\n"," [[0.54509804 0.51764706 0.54509804]\n","  [0.54117647 0.51372549 0.54117647]\n","  [0.53333333 0.50980392 0.5254902 ]\n","  ...\n","  [0.13333333 0.09019608 0.06666667]\n","  [0.14509804 0.10588235 0.07058824]\n","  [0.2        0.16078431 0.12156863]]\n","\n"," ...\n","\n"," [[0.60392157 0.65882353 0.6627451 ]\n","  [0.61960784 0.6745098  0.67843137]\n","  [0.56078431 0.60784314 0.60784314]\n","  ...\n","  [0.45882353 0.44313725 0.43921569]\n","  [0.40784314 0.38823529 0.37254902]\n","  [0.35294118 0.3254902  0.30196078]]\n","\n"," [[0.49803922 0.55294118 0.55686275]\n","  [0.60392157 0.65882353 0.65882353]\n","  [0.63529412 0.68235294 0.68235294]\n","  ...\n","  [0.51764706 0.51372549 0.49803922]\n","  [0.43921569 0.42745098 0.40784314]\n","  [0.37647059 0.35686275 0.34117647]]\n","\n"," [[0.4627451  0.50196078 0.50588235]\n","  [0.57254902 0.61176471 0.61568627]\n","  [0.66666667 0.70588235 0.70980392]\n","  ...\n","  [0.59607843 0.59215686 0.57647059]\n","  [0.47843137 0.46666667 0.44705882]\n","  [0.40392157 0.38431373 0.36862745]]]\n"]}],"source":["print(x_train_norm[0])"]},{"cell_type":"markdown","source":["- 이번 프로젝트에서 **어려웠던 점,**\n","\n","    1/4에 처음 읽어봤을 때는, 파이썬도 익숙하지 않았는데 혼자 코드를 해석하기 힘들었다. 가위, 바위, 보 라벨링을 하는 함수를 만드는 코드도 이해하지 못했어서 마지막 모델 학습 결과가 엉망으로 도출되었었다.<br>\n","    테스트 데이터셋으로 다른 조원분(이슬기님)의 사진을 받아서 진행하였는데, 그때도 가위, 바위, 보 라벨링 함수가 잘못된 듯 하였다.<br>\n","    모델을 만드는 함수는... 아예 이해를 포기하고 일단 지금 상황에서 이해할 수 있는 부분만 찬찬히 다시 보자고 생각하며, 1/5에 다시 라벨링 함수를 뜯어보고 이해한 대로 주석을 달며 진행하였다.\n"],"metadata":{"id":"l33sraZ_zYIH"},"id":"l33sraZ_zYIH"},{"cell_type":"markdown","source":["- 프로젝트를 진행하면서 **알아낸 점** 혹은 **아직 모호한 점**.\n","\n","1. 알아낸 점 : 가위, 바위, 보 라벨링하는 함수를 뜯어보고 이해하였다. 상세한 내용은 함수 안에 주석으로 설명을 달아 두었다.<br>\n","다만, 처음에는 함수 코드를 이해하지 못했어서 테스트 데이터셋 함수를 다시 만들고 사용하였는데, <u>찬찬히 뜯어보니 처음 트레인 데이터셋을 만들때 사용했던 함수를 재사용할 수 있을 듯 하여</u> 그렇게 사용하여 코드를 단축시켰다.\n","\n","2. 아직 모호한점 : 모델을 만드는 **케라스**에 대해서는 아직 전혀 모름"],"metadata":{"id":"TiOpqH42zbKZ"},"id":"TiOpqH42zbKZ"},{"cell_type":"markdown","source":["- 루브릭 평가 지표를 맞추기 위해 **시도한 것들**\n","\n","    1) 일단 먼저 가위바위보 라벨링 함수를 제대로 뜯어보고 이해했다. 처음에는 reshape가 안된줄 알고 다시 하는 등 이상한 시도를 많이 했으나, 다음날 다시 함수 코드를 보니 함수 안에서 제대로 reshape가 되어있었다.\n","\n","    2) 두번째로 코드를 고쳤을때, 평가 정확도가 0.93정도로 너무 높게 나와서 혹시 과적합 문제가 아닌가 하여, 학습을 할 때 validation 데이터셋을 만들어서 확인해 보았다. -> 과적합 문제는 아니었음\n","\n","    3) 언동 퍼실님과 다시 코드를 보니, 테스트 데이터셋이 잘못되어서 로드되지 않아서 문제가 생긴 듯하다는 결론이 났다. 다시 테스트 데이터셋의 변수가 잘못 입력된 것을 확인하여 알맞게 고쳤다.\n","\n","    4) 케라스 모델에 대해서 이해가 전무한 상황이긴 했지만...<br> n_channel_1=64, n_channel_2=128, n_dense=16 으로 입력했더니 가장 정확도가 높게 나왔다.\n","\n","    5) 모델학습에서 epoch수가 10으로 정해져 있었는데, 30으로 늘려서 정확도와 val_accuracy도 높은 것을 확인 하였다."],"metadata":{"id":"VaNF3MjDzdIJ"},"id":"VaNF3MjDzdIJ"},{"cell_type":"markdown","source":["- 만약에 루브릭 평가 관련 지표를 **달성 하지 못했을 때, 이유에 관한 추정**\n","\n","    아마도 학습 데이터셋은 직접 내가 찍은 사진이고, 테스트 데이터셋은 조원인 슬기님이 찍은 사진이어서 배경이 깔끔하지도 않고, 사진에 손 뿐만 아니라 다른 요소가 많았던 것이 원인이 아닐까 추정"],"metadata":{"id":"w5GcXw5_zeti"},"id":"w5GcXw5_zeti"},{"cell_type":"markdown","source":["- **자기 다짐**\n","\n","    앞으로 딥러닝의 케라스에 대해서 좀 더 공부하고 싶다는 생각이 들었다."],"metadata":{"id":"p_ZIRTazzhL3"},"id":"p_ZIRTazzhL3"},{"cell_type":"code","execution_count":null,"id":"75824bb2","metadata":{"id":"75824bb2"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"id":"9a3bfddc","metadata":{"id":"9a3bfddc"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"[E-01]RockPaperScissor.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}