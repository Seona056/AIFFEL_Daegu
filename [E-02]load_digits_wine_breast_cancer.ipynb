{"cells":[{"cell_type":"markdown","metadata":{"id":"kjZ22fcWuOha"},"source":["## 2-11. 프로젝트 (1) load_digits : 손글씨를 분류해 봅시다\n","\n","첫 번째 실습입니다.\n","\n","아까 잠깐 다뤄보았던 손글씨 이미지를 제대로 0~9까지 열 가지 카테고리로 분류해 보는 실습을 해 보겠습니다.\n","\n","다음 스텝을 참고해 jupyter notebook에 코드를 작성하여 제출해 주세요.\n","\n","<br>\n","\n","(1) 필요한 모듈 import하기"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":771,"status":"ok","timestamp":1641741961275,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"xA_j7Wc7tosF"},"outputs":[],"source":["from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"ylu-0aQ9udHD"},"source":["(2) 데이터 준비\n","\n","`load_digits` 메서드를 사용합니다."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1641741961277,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"m82J6x77uZYD"},"outputs":[],"source":["# loda_digits()의 인스턴스 digits를 생성한다.\n","digits = load_digits()"]},{"cell_type":"markdown","metadata":{"id":"Md3lfzgHuiSc"},"source":["(3) 데이터 이해하기\n","\n","지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n","\n","- Feature Data 지정하기\n","- Label Data 지정하기\n","- Target Names 출력해 보기\n","- 데이터 Describe 해 보기"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1641741961278,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"lxLwPQpOvK3C","outputId":"ec6d1176-4fd6-48ad-fa5a-5c372b8c5c7b"},"outputs":[{"data":{"text/plain":["['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# digits안에 어떤 변수와 메서드가 있는지 알아본다.\n","dir(digits)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":826,"status":"ok","timestamp":1641741962094,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"fQ_tn0NGzi0M","outputId":"12c96668-f1cb-4587-d9fb-163a9809a2f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1797, 64) : 64개의 특징을 가진 1797개의 행렬 데이터 (2차원 배열)\n","(1797,) : 라벨값은 1차원 벡터이다.\n","라벨 종류 : [0 1 2 3 4 5 6 7 8 9]\n","1797개의 데이터를 10가지로 분류하는 모델이 필요\n"]}],"source":["digits_data = digits.data\n","digits_feature_names = digits.feature_names\n","digits_label = digits.target\n","digits_label_names = digits.target_names\n","\n","print(digits_data.shape, f': {digits_data.shape[1]}개의 특징을 가진 {digits_data.shape[0]}개의 행렬 데이터 (2차원 배열)')\n","print(digits_label.shape, ': 라벨값은 1차원 벡터이다.')\n","print(f'라벨 종류 : {digits_label_names}')\n","print(f'{digits_data.shape[0]}개의 데이터를 {len(digits_label_names)}가지로 분류하는 모델이 필요')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1641741962095,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"G92avh2Z0_9l","outputId":"311af079-eb93-4c7f-c917-17caf97ceae7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n"," [ 0.  0. 13. 15. 10. 15.  5.  0.]\n"," [ 0.  3. 15.  2.  0. 11.  8.  0.]\n"," [ 0.  4. 12.  0.  0.  8.  8.  0.]\n"," [ 0.  5.  8.  0.  0.  9.  8.  0.]\n"," [ 0.  4. 11.  0.  1. 12.  7.  0.]\n"," [ 0.  2. 14.  5. 10. 12.  0.  0.]\n"," [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"]}],"source":["# 이미지\n","digits_images = digits.images\n","print(digits_images[0])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1641741962097,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"OPZl41IDGo5U","outputId":"4f9e3f72-0b74-4a12-f164-88c3d5f8f31e"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-d864ec7e-0e81-415a-b0be-37a5abc6e7c4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pixel_0_0</th>\n","      <th>pixel_0_1</th>\n","      <th>pixel_0_2</th>\n","      <th>pixel_0_3</th>\n","      <th>pixel_0_4</th>\n","      <th>pixel_0_5</th>\n","      <th>pixel_0_6</th>\n","      <th>pixel_0_7</th>\n","      <th>pixel_1_0</th>\n","      <th>pixel_1_1</th>\n","      <th>pixel_1_2</th>\n","      <th>pixel_1_3</th>\n","      <th>pixel_1_4</th>\n","      <th>pixel_1_5</th>\n","      <th>pixel_1_6</th>\n","      <th>pixel_1_7</th>\n","      <th>pixel_2_0</th>\n","      <th>pixel_2_1</th>\n","      <th>pixel_2_2</th>\n","      <th>pixel_2_3</th>\n","      <th>pixel_2_4</th>\n","      <th>pixel_2_5</th>\n","      <th>pixel_2_6</th>\n","      <th>pixel_2_7</th>\n","      <th>pixel_3_0</th>\n","      <th>pixel_3_1</th>\n","      <th>pixel_3_2</th>\n","      <th>pixel_3_3</th>\n","      <th>pixel_3_4</th>\n","      <th>pixel_3_5</th>\n","      <th>pixel_3_6</th>\n","      <th>pixel_3_7</th>\n","      <th>pixel_4_0</th>\n","      <th>pixel_4_1</th>\n","      <th>pixel_4_2</th>\n","      <th>pixel_4_3</th>\n","      <th>pixel_4_4</th>\n","      <th>pixel_4_5</th>\n","      <th>pixel_4_6</th>\n","      <th>pixel_4_7</th>\n","      <th>pixel_5_0</th>\n","      <th>pixel_5_1</th>\n","      <th>pixel_5_2</th>\n","      <th>pixel_5_3</th>\n","      <th>pixel_5_4</th>\n","      <th>pixel_5_5</th>\n","      <th>pixel_5_6</th>\n","      <th>pixel_5_7</th>\n","      <th>pixel_6_0</th>\n","      <th>pixel_6_1</th>\n","      <th>pixel_6_2</th>\n","      <th>pixel_6_3</th>\n","      <th>pixel_6_4</th>\n","      <th>pixel_6_5</th>\n","      <th>pixel_6_6</th>\n","      <th>pixel_6_7</th>\n","      <th>pixel_7_0</th>\n","      <th>pixel_7_1</th>\n","      <th>pixel_7_2</th>\n","      <th>pixel_7_3</th>\n","      <th>pixel_7_4</th>\n","      <th>pixel_7_5</th>\n","      <th>pixel_7_6</th>\n","      <th>pixel_7_7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>13.0</td>\n","      <td>9.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>13.0</td>\n","      <td>15.0</td>\n","      <td>10.0</td>\n","      <td>15.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>15.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>12.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>14.0</td>\n","      <td>5.0</td>\n","      <td>10.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>13.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>13.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>16.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>15.0</td>\n","      <td>16.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>15.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>16.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>15.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>16.0</td>\n","      <td>15.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>13.0</td>\n","      <td>8.0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>15.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>8.0</td>\n","      <td>13.0</td>\n","      <td>15.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>13.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>11.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>11.0</td>\n","      <td>16.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>15.0</td>\n","      <td>13.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>13.0</td>\n","      <td>6.0</td>\n","      <td>15.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>13.0</td>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>15.0</td>\n","      <td>11.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>12.0</td>\n","      <td>12.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>10.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>14.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>13.0</td>\n","      <td>13.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>13.0</td>\n","      <td>6.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>16.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>15.0</td>\n","      <td>16.0</td>\n","      <td>13.0</td>\n","      <td>16.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>15.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>16.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1792</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>13.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>16.0</td>\n","      <td>14.0</td>\n","      <td>12.0</td>\n","      <td>16.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>16.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>16.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>16.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>7.0</td>\n","      <td>16.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>14.0</td>\n","      <td>15.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1793</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>16.0</td>\n","      <td>13.0</td>\n","      <td>11.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>15.0</td>\n","      <td>12.0</td>\n","      <td>16.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>16.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>13.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>16.0</td>\n","      <td>7.0</td>\n","      <td>9.0</td>\n","      <td>16.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>15.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>16.0</td>\n","      <td>14.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1794</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11.0</td>\n","      <td>15.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>13.0</td>\n","      <td>16.0</td>\n","      <td>8.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>15.0</td>\n","      <td>10.0</td>\n","      <td>16.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>14.0</td>\n","      <td>16.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>13.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1795</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>10.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>15.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>16.0</td>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>16.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>16.0</td>\n","      <td>10.0</td>\n","      <td>7.0</td>\n","      <td>16.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>16.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>7.0</td>\n","      <td>7.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>12.0</td>\n","      <td>16.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1796</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>14.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>16.0</td>\n","      <td>14.0</td>\n","      <td>6.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>8.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>16.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>16.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>16.0</td>\n","      <td>10.0</td>\n","      <td>8.0</td>\n","      <td>16.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>8.0</td>\n","      <td>12.0</td>\n","      <td>14.0</td>\n","      <td>12.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1797 rows × 64 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d864ec7e-0e81-415a-b0be-37a5abc6e7c4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d864ec7e-0e81-415a-b0be-37a5abc6e7c4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d864ec7e-0e81-415a-b0be-37a5abc6e7c4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      pixel_0_0  pixel_0_1  pixel_0_2  ...  pixel_7_5  pixel_7_6  pixel_7_7\n","0           0.0        0.0        5.0  ...        0.0        0.0        0.0\n","1           0.0        0.0        0.0  ...       10.0        0.0        0.0\n","2           0.0        0.0        0.0  ...       16.0        9.0        0.0\n","3           0.0        0.0        7.0  ...        9.0        0.0        0.0\n","4           0.0        0.0        0.0  ...        4.0        0.0        0.0\n","...         ...        ...        ...  ...        ...        ...        ...\n","1792        0.0        0.0        4.0  ...        9.0        0.0        0.0\n","1793        0.0        0.0        6.0  ...        6.0        0.0        0.0\n","1794        0.0        0.0        1.0  ...        6.0        0.0        0.0\n","1795        0.0        0.0        2.0  ...       12.0        0.0        0.0\n","1796        0.0        0.0       10.0  ...       12.0        1.0        0.0\n","\n","[1797 rows x 64 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","digits_df = pd.DataFrame(data=digits_data, columns=digits.feature_names)\n","digits_df"]},{"cell_type":"markdown","metadata":{"id":"_nGkCLGRvLhK"},"source":["(4) train, test 데이터 분리\n","\n","모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n","X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1641741962098,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"i0F3HHSDvMX4"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.3, random_state=20)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1641741962099,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"UY_ClvUvvNhl","outputId":"c1b8deb9-70a3-499f-d7a1-50521b6a4450"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1257, 64) (1257,)\n","(540, 64) (540,)\n"]}],"source":["print(x_train.shape, y_train.shape)\n","print(x_test.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"XrJjd5XpqR4w"},"source":["(5) 다양한 모델로 학습시켜보기\n","학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n","\n","- Decision Tree 사용해 보기\n","- Random Forest 사용해 보기\n","- SVM 사용해 보기\n","- SGD Classifier 사용해 보기\n","- Logistic Regression 사용해 보기"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1641741962100,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"RXbOY4_1vdUv","outputId":"1543d1e5-f793-4203-d68a-c725e567ee3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","DecisionTreeClassifier 분류 모델이다.\n","\n","\n","정답률 : 0.8425925925925926\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97        50\n","           1       0.75      0.84      0.79        56\n","           2       0.77      0.82      0.79        44\n","           3       0.85      0.81      0.83        63\n","           4       0.84      0.87      0.85        60\n","           5       0.90      0.84      0.87        51\n","           6       0.96      0.86      0.91        59\n","           7       0.87      0.85      0.86        53\n","           8       0.73      0.77      0.75        52\n","           9       0.81      0.83      0.82        52\n","\n","    accuracy                           0.84       540\n","   macro avg       0.85      0.84      0.84       540\n","weighted avg       0.85      0.84      0.84       540\n","\n"]}],"source":["# Decision Tree\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","decision_tree = DecisionTreeClassifier(random_state=20)\n","print(decision_tree._estimator_type)\n","print('DecisionTreeClassifier 분류 모델이다.')\n","\n","# 모델 학습\n","# 모델이름.fit(학습데이터셋, 테스트 데이터셋)\n","# 딥러닝에서는 모델을 직접 구성했으나, decicion tree는 이미 만들어진 모델이기 때문에 import해서 사용하면 된다.\n","decision_tree.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_decision = decision_tree.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_decision))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_decision))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":620,"status":"ok","timestamp":1641741962708,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"dkl1FJ003ZGo","outputId":"73ddd07d-6e47-461c-af00-530dd88dc117"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","RandomForestClassifier 분류 모델이다.\n","\n","\n","정답률 : 0.9703703703703703\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        50\n","           1       0.96      0.98      0.97        56\n","           2       1.00      1.00      1.00        44\n","           3       0.98      0.95      0.97        63\n","           4       1.00      0.98      0.99        60\n","           5       0.94      0.96      0.95        51\n","           6       0.98      0.95      0.97        59\n","           7       0.96      0.98      0.97        53\n","           8       0.94      0.94      0.94        52\n","           9       0.94      0.96      0.95        52\n","\n","    accuracy                           0.97       540\n","   macro avg       0.97      0.97      0.97       540\n","weighted avg       0.97      0.97      0.97       540\n","\n"]}],"source":["# Random Forest\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","random_forest = RandomForestClassifier(random_state=20)\n","print(random_forest._estimator_type)\n","print('RandomForestClassifier 분류 모델이다.')\n","\n","# 모델 학습\n","random_forest.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_random = random_forest.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_random))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_random))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1641741962709,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"iY9BuAEu3gLs","outputId":"57c96cb0-e0e5-4b2c-c363-8bcef0e123c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","Support Vector Machine 분류 모델이다.\n","\n","\n","정답률 : 0.9796296296296296\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        50\n","           1       0.98      1.00      0.99        56\n","           2       1.00      1.00      1.00        44\n","           3       1.00      0.95      0.98        63\n","           4       1.00      0.98      0.99        60\n","           5       0.94      0.98      0.96        51\n","           6       1.00      0.97      0.98        59\n","           7       0.98      0.98      0.98        53\n","           8       0.94      0.98      0.96        52\n","           9       0.94      0.96      0.95        52\n","\n","    accuracy                           0.98       540\n","   macro avg       0.98      0.98      0.98       540\n","weighted avg       0.98      0.98      0.98       540\n","\n"]}],"source":["# 서포트 벡터 머신(SVM, Support Vector Machine)\n","\n","import sklearn.svm as svm\n","\n","svm = svm.SVC()\n","print(svm._estimator_type)\n","print('Support Vector Machine 분류 모델이다.')\n","\n","# 모델 학습\n","svm.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_svm = svm.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_svm))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_svm))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1641741962710,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"St9rFF6q33wY","outputId":"521c5e40-127b-47b2-ab42-2b0c0c05ac50"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","Stochastic Gradient Descent 분류 모델이다.\n","\n","\n","정답률 : 0.9296296296296296\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        50\n","           1       0.71      1.00      0.83        56\n","           2       1.00      0.95      0.98        44\n","           3       0.98      0.90      0.94        63\n","           4       0.97      0.95      0.96        60\n","           5       0.96      0.96      0.96        51\n","           6       1.00      0.95      0.97        59\n","           7       0.98      0.94      0.96        53\n","           8       0.88      0.71      0.79        52\n","           9       0.92      0.92      0.92        52\n","\n","    accuracy                           0.93       540\n","   macro avg       0.94      0.93      0.93       540\n","weighted avg       0.94      0.93      0.93       540\n","\n"]}],"source":["# 확률적 경사 하강법 (SGD, Stochastic Gradient Descent)\n","\n","from sklearn.linear_model import SGDClassifier\n","\n","sgd = SGDClassifier()\n","print(sgd._estimator_type)\n","print('Stochastic Gradient Descent 분류 모델이다.')\n","\n","# 모델 학습\n","sgd.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_sgd = sgd.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_sgd))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_sgd))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5131,"status":"ok","timestamp":1641741967829,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"S4OkyHpE44vO","outputId":"fae3da61-5b52-4ef8-962f-a0e4274e3539"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","LogisticRegression 분류 모델이다.\n","\n","\n","정답률 : 0.9722222222222222\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        50\n","           1       0.96      0.98      0.97        56\n","           2       1.00      1.00      1.00        44\n","           3       0.97      0.97      0.97        63\n","           4       0.98      0.98      0.98        60\n","           5       0.93      0.98      0.95        51\n","           6       1.00      0.95      0.97        59\n","           7       0.98      0.96      0.97        53\n","           8       0.96      0.98      0.97        52\n","           9       0.94      0.92      0.93        52\n","\n","    accuracy                           0.97       540\n","   macro avg       0.97      0.97      0.97       540\n","weighted avg       0.97      0.97      0.97       540\n","\n"]}],"source":["# Logistic Regression\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","logistic = LogisticRegression(max_iter=7000)\n","print(logistic._estimator_type)\n","print('LogisticRegression 분류 모델이다.')\n","\n","# 모델 학습\n","logistic.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_logistic = logistic.predict(x_test)\n","\n","# 정확도\n","from sklearn.metrics import accuracy_score\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_logistic))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_logistic))"]},{"cell_type":"markdown","metadata":{"id":"vtPJ33D0qW0U"},"source":["(6) 모델을 평가해 보기\n","\n","학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NInU3RWXFUuv"},"source":["**My Answer** : \n","\n","SVM의 recall 지표가 가장 적절하다고 생각했다.\n","리콜 지표는 FN (맞는 것이 틀리다고 판정되는 것)이 낮을 수록 높아지는 지표인데, 손글씨 인식을 만약 태블릿에서 인식되는 경우로 생각해 본다면 맞게 쓴 글씨를 잘 인식해서 표현되는 것이 중요하지 않을까 생각했기 때문이다.\n","\n","그리고 어느 한 라벨의 리콜값이 중요하지 않기 때문에, 리콜값 전체 평균인 macro-avg값을 척도로 선정하였다.\n","\n","<u>***SVM의 macro-avg : 0.98***</u>"]},{"cell_type":"markdown","metadata":{"id":"DnFEshWzqdQD"},"source":["# 2-12. 프로젝트 (2) load_wine : 와인을 분류해 봅시다\n","\n","이번에는 와인 데이터입니다. 와인의 어떤 특징으로 와인의 종류를 분류해 볼 수 있을까요?\n","\n","데이터에 어떤 정보가 담겨있는지, feature는 무엇이고 label은 무엇인지 확인해 보면서 진행하는 점, 잊지마세요!"]},{"cell_type":"markdown","metadata":{"id":"AZPOw2lZFozm"},"source":["(1) 필요한 모듈 import하기"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":66,"status":"ok","timestamp":1641741967830,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"Fc0Ec-NWFXRI"},"outputs":[],"source":["from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"8ILPctoxF2xZ"},"source":["(2) 데이터 준비\n","\n","`load_wine` 메서드를 사용합니다."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":66,"status":"ok","timestamp":1641741967832,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"sfpxugmbKBhV"},"outputs":[],"source":["# loda_wine()의 인스턴스 wine 생성한다.\n","wine = load_wine()"]},{"cell_type":"markdown","metadata":{"id":"NaE9cE5aGKhE"},"source":["(3) 데이터 이해하기\n","\n","지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n","\n","- Feature Data 지정하기\n","- Label Data 지정하기\n","- Target Names 출력해 보기\n","- 데이터 Describe 해 보기"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1641741967833,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"yT2WROxoIpE5","outputId":"79ccf3c4-e7dc-476c-caf3-17ba21086309"},"outputs":[{"data":{"text/plain":["['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# wine안에 어떤 변수와 메서드가 있는지 알아본다.\n","dir(wine)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61,"status":"ok","timestamp":1641741967833,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"93UgV16RNcQI","outputId":"aa284d90-8221-4158-90c9-b5fd7587c9e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(178, 13) : 13개의 특징을 가진 178개의 와인 데이터 (2차원 배열)\n","(178,) : 라벨값은 1차원 벡터이다.\n","라벨 종류 : ['class_0' 'class_1' 'class_2']\n","178개의 와인을 3가지의 와인으로 분류하는 모델이 필요\n"]}],"source":["wine_data = wine.data\n","wine_feature_names = wine.feature_names\n","wine_label = wine.target\n","wine_label_names = wine.target_names\n","\n","print(wine_data.shape, ': 13개의 특징을 가진 178개의 와인 데이터 (2차원 배열)')\n","print(wine_label.shape, ': 라벨값은 1차원 벡터이다.')\n","print(f'라벨 종류 : {wine_label_names}')\n","print('178개의 와인을 3가지의 와인으로 분류하는 모델이 필요')"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1641741967834,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"XHQBeWKgGVpj","outputId":"325aa383-d781-4275-ee76-d63fcae46464"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-b5ff50d5-ffe0-4e90-bfa1-349add592173\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alcohol</th>\n","      <th>malic_acid</th>\n","      <th>ash</th>\n","      <th>alcalinity_of_ash</th>\n","      <th>magnesium</th>\n","      <th>total_phenols</th>\n","      <th>flavanoids</th>\n","      <th>nonflavanoid_phenols</th>\n","      <th>proanthocyanins</th>\n","      <th>color_intensity</th>\n","      <th>hue</th>\n","      <th>od280/od315_of_diluted_wines</th>\n","      <th>proline</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14.23</td>\n","      <td>1.71</td>\n","      <td>2.43</td>\n","      <td>15.6</td>\n","      <td>127.0</td>\n","      <td>2.80</td>\n","      <td>3.06</td>\n","      <td>0.28</td>\n","      <td>2.29</td>\n","      <td>5.64</td>\n","      <td>1.04</td>\n","      <td>3.92</td>\n","      <td>1065.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13.20</td>\n","      <td>1.78</td>\n","      <td>2.14</td>\n","      <td>11.2</td>\n","      <td>100.0</td>\n","      <td>2.65</td>\n","      <td>2.76</td>\n","      <td>0.26</td>\n","      <td>1.28</td>\n","      <td>4.38</td>\n","      <td>1.05</td>\n","      <td>3.40</td>\n","      <td>1050.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13.16</td>\n","      <td>2.36</td>\n","      <td>2.67</td>\n","      <td>18.6</td>\n","      <td>101.0</td>\n","      <td>2.80</td>\n","      <td>3.24</td>\n","      <td>0.30</td>\n","      <td>2.81</td>\n","      <td>5.68</td>\n","      <td>1.03</td>\n","      <td>3.17</td>\n","      <td>1185.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14.37</td>\n","      <td>1.95</td>\n","      <td>2.50</td>\n","      <td>16.8</td>\n","      <td>113.0</td>\n","      <td>3.85</td>\n","      <td>3.49</td>\n","      <td>0.24</td>\n","      <td>2.18</td>\n","      <td>7.80</td>\n","      <td>0.86</td>\n","      <td>3.45</td>\n","      <td>1480.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13.24</td>\n","      <td>2.59</td>\n","      <td>2.87</td>\n","      <td>21.0</td>\n","      <td>118.0</td>\n","      <td>2.80</td>\n","      <td>2.69</td>\n","      <td>0.39</td>\n","      <td>1.82</td>\n","      <td>4.32</td>\n","      <td>1.04</td>\n","      <td>2.93</td>\n","      <td>735.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>173</th>\n","      <td>13.71</td>\n","      <td>5.65</td>\n","      <td>2.45</td>\n","      <td>20.5</td>\n","      <td>95.0</td>\n","      <td>1.68</td>\n","      <td>0.61</td>\n","      <td>0.52</td>\n","      <td>1.06</td>\n","      <td>7.70</td>\n","      <td>0.64</td>\n","      <td>1.74</td>\n","      <td>740.0</td>\n","    </tr>\n","    <tr>\n","      <th>174</th>\n","      <td>13.40</td>\n","      <td>3.91</td>\n","      <td>2.48</td>\n","      <td>23.0</td>\n","      <td>102.0</td>\n","      <td>1.80</td>\n","      <td>0.75</td>\n","      <td>0.43</td>\n","      <td>1.41</td>\n","      <td>7.30</td>\n","      <td>0.70</td>\n","      <td>1.56</td>\n","      <td>750.0</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>13.27</td>\n","      <td>4.28</td>\n","      <td>2.26</td>\n","      <td>20.0</td>\n","      <td>120.0</td>\n","      <td>1.59</td>\n","      <td>0.69</td>\n","      <td>0.43</td>\n","      <td>1.35</td>\n","      <td>10.20</td>\n","      <td>0.59</td>\n","      <td>1.56</td>\n","      <td>835.0</td>\n","    </tr>\n","    <tr>\n","      <th>176</th>\n","      <td>13.17</td>\n","      <td>2.59</td>\n","      <td>2.37</td>\n","      <td>20.0</td>\n","      <td>120.0</td>\n","      <td>1.65</td>\n","      <td>0.68</td>\n","      <td>0.53</td>\n","      <td>1.46</td>\n","      <td>9.30</td>\n","      <td>0.60</td>\n","      <td>1.62</td>\n","      <td>840.0</td>\n","    </tr>\n","    <tr>\n","      <th>177</th>\n","      <td>14.13</td>\n","      <td>4.10</td>\n","      <td>2.74</td>\n","      <td>24.5</td>\n","      <td>96.0</td>\n","      <td>2.05</td>\n","      <td>0.76</td>\n","      <td>0.56</td>\n","      <td>1.35</td>\n","      <td>9.20</td>\n","      <td>0.61</td>\n","      <td>1.60</td>\n","      <td>560.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>178 rows × 13 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5ff50d5-ffe0-4e90-bfa1-349add592173')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b5ff50d5-ffe0-4e90-bfa1-349add592173 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b5ff50d5-ffe0-4e90-bfa1-349add592173');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     alcohol  malic_acid   ash  ...   hue  od280/od315_of_diluted_wines  proline\n","0      14.23        1.71  2.43  ...  1.04                          3.92   1065.0\n","1      13.20        1.78  2.14  ...  1.05                          3.40   1050.0\n","2      13.16        2.36  2.67  ...  1.03                          3.17   1185.0\n","3      14.37        1.95  2.50  ...  0.86                          3.45   1480.0\n","4      13.24        2.59  2.87  ...  1.04                          2.93    735.0\n","..       ...         ...   ...  ...   ...                           ...      ...\n","173    13.71        5.65  2.45  ...  0.64                          1.74    740.0\n","174    13.40        3.91  2.48  ...  0.70                          1.56    750.0\n","175    13.27        4.28  2.26  ...  0.59                          1.56    835.0\n","176    13.17        2.59  2.37  ...  0.60                          1.62    840.0\n","177    14.13        4.10  2.74  ...  0.61                          1.60    560.0\n","\n","[178 rows x 13 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","wine_df = pd.DataFrame(data=wine.data, columns=wine_feature_names)\n","wine_df"]},{"cell_type":"markdown","metadata":{"id":"jsrq7PzpGV60"},"source":["(4) train, test 데이터 분리\n","\n","모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n","X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요."]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1641741967834,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"tpAB01BQGWYZ"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.3, random_state=20)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1641741967835,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"TFb4xLYp1Q89","outputId":"abd2676c-6315-4c33-9484-e75775eeb6c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["(124, 13) (124,)\n","(54, 13) (54,)\n"]}],"source":["print(x_train.shape, y_train.shape)\n","print(x_test.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"2uxUksYfGb3t"},"source":["(5) 다양한 모델로 학습시켜보기\n","학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n","\n","- Decision Tree 사용해 보기\n","- Random Forest 사용해 보기\n","- SVM 사용해 보기\n","- SGD Classifier 사용해 보기\n","- Logistic Regression 사용해 보기"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1641741967835,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"HIpmrlsUOIFF","outputId":"0cdfa0dd-31e3-492d-b5d5-fe1fd4d9d6ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","DecisionTreeClassifier 분류 모델이다.\n","\n","\n","정답률 : 0.9629629629629629\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.93      0.93        15\n","           1       0.96      0.96      0.96        27\n","           2       1.00      1.00      1.00        12\n","\n","    accuracy                           0.96        54\n","   macro avg       0.97      0.97      0.97        54\n","weighted avg       0.96      0.96      0.96        54\n","\n"]}],"source":["# Decision Tree\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","decision_tree = DecisionTreeClassifier(random_state=20)\n","print(decision_tree._estimator_type)\n","print('DecisionTreeClassifier 분류 모델이다.')\n","\n","# 모델 학습\n","decision_tree.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_decision = decision_tree.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_decision))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_decision))"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1641741967836,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"jvVv8tiPOtb5","outputId":"6e4f48b1-82f3-4c3c-85a5-fea0f712753e"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","RandomForestClassifier 분류 모델이다.\n","\n","\n","정답률 : 1.0\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        15\n","           1       1.00      1.00      1.00        27\n","           2       1.00      1.00      1.00        12\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n"]}],"source":["# Random Forest\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","random_forest = RandomForestClassifier(random_state=20)\n","print(random_forest._estimator_type)\n","print('RandomForestClassifier 분류 모델이다.')\n","\n","# 모델 학습\n","random_forest.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_random = random_forest.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_random))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_random))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1641741967837,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"DvKABMK1TJ96","outputId":"cf585b26-dad1-4ea7-b881-5467e304432a"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","Support Vector Machine 분류 모델이다.\n","\n","\n","정답률 : 0.7037037037037037\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.87      0.93        15\n","           1       0.78      0.67      0.72        27\n","           2       0.39      0.58      0.47        12\n","\n","    accuracy                           0.70        54\n","   macro avg       0.72      0.71      0.71        54\n","weighted avg       0.76      0.70      0.72        54\n","\n"]}],"source":["# 서포트 벡터 머신(SVM, Support Vector Machine)\n","\n","import sklearn.svm as svm\n","\n","svm = svm.SVC()\n","print(svm._estimator_type)\n","print('Support Vector Machine 분류 모델이다.')\n","\n","# 모델 학습\n","svm.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_svm = svm.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_svm))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_svm))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1641741968465,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"tUGOZB8SNjin","outputId":"73da88ea-7b89-4db1-d58d-a4ee15cd4c28"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","Stochastic Gradient Descent 분류 모델이다.\n","\n","\n","정답률 : 0.5\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.87      0.87        15\n","           1       0.80      0.15      0.25        27\n","           2       0.29      0.83      0.43        12\n","\n","    accuracy                           0.50        54\n","   macro avg       0.65      0.62      0.52        54\n","weighted avg       0.71      0.50      0.46        54\n","\n"]}],"source":["# 확률적 경사 하강법 (SGD, Stochastic Gradient Descent)\n","\n","from sklearn.linear_model import SGDClassifier\n","\n","sgd = SGDClassifier()\n","print(sgd._estimator_type)\n","print('Stochastic Gradient Descent 분류 모델이다.')\n","\n","# 모델 학습\n","sgd.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_sgd = sgd.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_sgd))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_sgd))"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":614,"status":"ok","timestamp":1641741969058,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"6dXIBLSpNsiz","outputId":"8bdd78ca-d69c-40f9-8322-99442824f92e"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","LogisticRegression 분류 모델이다.\n","\n","\n","정답률 : 1.0\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        15\n","           1       1.00      1.00      1.00        27\n","           2       1.00      1.00      1.00        12\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n"]}],"source":["# Logistic Regression\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","logistic = LogisticRegression(max_iter=7000)\n","print(logistic._estimator_type)\n","print('LogisticRegression 분류 모델이다.')\n","\n","# 모델 학습\n","logistic.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_logistic = logistic.predict(x_test)\n","\n","# 정확도\n","from sklearn.metrics import accuracy_score\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_logistic))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_logistic))"]},{"cell_type":"markdown","metadata":{"id":"3PM1NKoA7cw6"},"source":["(6) 모델을 평가해 보기\n","\n","학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sHCTo8ekR3Tr"},"source":["**My Answer** : \n","\n","전체 정확도인 accuracy지표를 중점으로 보았다. 와인분류는 recall과 precision 모두 중요한 지표라고 보았고, 그 모두를 중요하게 보기 위해서는 f1-score를 봐야했다. 그리고 한가지 라벨의 지표가 중요한 것이 아니어서 f1-score의 평균과 accuracy를 중요 지표로 보았고, Random Forest와 Logistic Regression이 모든 지표가 1이 나왔다.\n","\n","<u>***Random Forest, Logistic Regression : 1.0***</u>"]},{"cell_type":"markdown","metadata":{"id":"5fPuwQ76qsHD"},"source":["# 2-13. 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다\n","\n","마지막으로 유방암 여부를 진단해 보겠습니다.\n","이 데이터 또한 여러 사람의 건강 지표에 대한 데이터가 feature로 들어가있고, 유방암의 여부가 True, False로 label이 됩니다.\n","\n","주어진 데이터로 환자의 유방암 여부를 분류해 볼 수 있을까요?\n","\n","(1) 필요한 모듈 import하기"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1641741969059,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"YkSWXN04F54l"},"outputs":[],"source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"O0i9gbu9F6Xh"},"source":["(2) 데이터 준비\n","\n","`load_breast_cancer()` 메서드를 사용합니다."]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1641741969060,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"MBpFpNhWGQyl"},"outputs":[],"source":["# loda_breast_cancer()의 인스턴스 cancer 생성한다.\n","cancer = load_breast_cancer()"]},{"cell_type":"markdown","metadata":{"id":"PU7Jt89ZGRP7"},"source":["(3) 데이터 이해하기\n","\n","지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n","\n","- Feature Data 지정하기\n","- Label Data 지정하기\n","- Target Names 출력해 보기\n","- 데이터 Describe 해 보기"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":733,"status":"ok","timestamp":1641741969785,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"YVNeq6l-GefE","outputId":"8838e55a-d479-45a0-e063-c35cee07e319"},"outputs":[{"data":{"text/plain":["['DESCR',\n"," 'data',\n"," 'data_module',\n"," 'feature_names',\n"," 'filename',\n"," 'frame',\n"," 'target',\n"," 'target_names']"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# cancer안에 어떤 변수와 메서드가 있는지 알아본다.\n","dir(cancer)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1641741969786,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"ICeCSlTZ85af","outputId":"7b18e5ba-5291-4f3a-9817-34c6fb3b9c12"},"outputs":[{"name":"stdout","output_type":"stream","text":["(569, 30) : 30개의 특징을 가진 569개의 행렬 데이터 (2차원 배열)\n","(569,) : 라벨값은 1차원 벡터이다.\n","라벨 종류 : ['malignant' 'benign']\n","569개의 데이터를 2가지로 분류하는 모델이 필요\n"]}],"source":["cancer_data = cancer.data\n","cancer_feature_names = cancer.feature_names\n","cancer_label = cancer.target\n","cancer_label_names = cancer.target_names\n","\n","print(cancer_data.shape, f': {cancer_data.shape[1]}개의 특징을 가진 {cancer_data.shape[0]}개의 행렬 데이터 (2차원 배열)')\n","print(cancer_label.shape, ': 라벨값은 1차원 벡터이다.')\n","print(f'라벨 종류 : {cancer_label_names}')\n","print(f'{cancer_data.shape[0]}개의 데이터를 {len(cancer_label_names)}가지로 분류하는 모델이 필요')"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":522},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1641741969788,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"YjzE_Kbp95rT","outputId":"c4b02a55-5e98-4b6b-9a35-b971c31a9b2b"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-506415a5-daee-4058-b6d4-315a10cee594\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean radius</th>\n","      <th>mean texture</th>\n","      <th>mean perimeter</th>\n","      <th>mean area</th>\n","      <th>mean smoothness</th>\n","      <th>mean compactness</th>\n","      <th>mean concavity</th>\n","      <th>mean concave points</th>\n","      <th>mean symmetry</th>\n","      <th>mean fractal dimension</th>\n","      <th>radius error</th>\n","      <th>texture error</th>\n","      <th>perimeter error</th>\n","      <th>area error</th>\n","      <th>smoothness error</th>\n","      <th>compactness error</th>\n","      <th>concavity error</th>\n","      <th>concave points error</th>\n","      <th>symmetry error</th>\n","      <th>fractal dimension error</th>\n","      <th>worst radius</th>\n","      <th>worst texture</th>\n","      <th>worst perimeter</th>\n","      <th>worst area</th>\n","      <th>worst smoothness</th>\n","      <th>worst compactness</th>\n","      <th>worst concavity</th>\n","      <th>worst concave points</th>\n","      <th>worst symmetry</th>\n","      <th>worst fractal dimension</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>1.0950</td>\n","      <td>0.9053</td>\n","      <td>8.589</td>\n","      <td>153.40</td>\n","      <td>0.006399</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.006193</td>\n","      <td>25.380</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.990</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.570</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.910</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.540</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>21.56</td>\n","      <td>22.39</td>\n","      <td>142.00</td>\n","      <td>1479.0</td>\n","      <td>0.11100</td>\n","      <td>0.11590</td>\n","      <td>0.24390</td>\n","      <td>0.13890</td>\n","      <td>0.1726</td>\n","      <td>0.05623</td>\n","      <td>1.1760</td>\n","      <td>1.2560</td>\n","      <td>7.673</td>\n","      <td>158.70</td>\n","      <td>0.010300</td>\n","      <td>0.02891</td>\n","      <td>0.05198</td>\n","      <td>0.02454</td>\n","      <td>0.01114</td>\n","      <td>0.004239</td>\n","      <td>25.450</td>\n","      <td>26.40</td>\n","      <td>166.10</td>\n","      <td>2027.0</td>\n","      <td>0.14100</td>\n","      <td>0.21130</td>\n","      <td>0.4107</td>\n","      <td>0.2216</td>\n","      <td>0.2060</td>\n","      <td>0.07115</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>20.13</td>\n","      <td>28.25</td>\n","      <td>131.20</td>\n","      <td>1261.0</td>\n","      <td>0.09780</td>\n","      <td>0.10340</td>\n","      <td>0.14400</td>\n","      <td>0.09791</td>\n","      <td>0.1752</td>\n","      <td>0.05533</td>\n","      <td>0.7655</td>\n","      <td>2.4630</td>\n","      <td>5.203</td>\n","      <td>99.04</td>\n","      <td>0.005769</td>\n","      <td>0.02423</td>\n","      <td>0.03950</td>\n","      <td>0.01678</td>\n","      <td>0.01898</td>\n","      <td>0.002498</td>\n","      <td>23.690</td>\n","      <td>38.25</td>\n","      <td>155.00</td>\n","      <td>1731.0</td>\n","      <td>0.11660</td>\n","      <td>0.19220</td>\n","      <td>0.3215</td>\n","      <td>0.1628</td>\n","      <td>0.2572</td>\n","      <td>0.06637</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>16.60</td>\n","      <td>28.08</td>\n","      <td>108.30</td>\n","      <td>858.1</td>\n","      <td>0.08455</td>\n","      <td>0.10230</td>\n","      <td>0.09251</td>\n","      <td>0.05302</td>\n","      <td>0.1590</td>\n","      <td>0.05648</td>\n","      <td>0.4564</td>\n","      <td>1.0750</td>\n","      <td>3.425</td>\n","      <td>48.55</td>\n","      <td>0.005903</td>\n","      <td>0.03731</td>\n","      <td>0.04730</td>\n","      <td>0.01557</td>\n","      <td>0.01318</td>\n","      <td>0.003892</td>\n","      <td>18.980</td>\n","      <td>34.12</td>\n","      <td>126.70</td>\n","      <td>1124.0</td>\n","      <td>0.11390</td>\n","      <td>0.30940</td>\n","      <td>0.3403</td>\n","      <td>0.1418</td>\n","      <td>0.2218</td>\n","      <td>0.07820</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>20.60</td>\n","      <td>29.33</td>\n","      <td>140.10</td>\n","      <td>1265.0</td>\n","      <td>0.11780</td>\n","      <td>0.27700</td>\n","      <td>0.35140</td>\n","      <td>0.15200</td>\n","      <td>0.2397</td>\n","      <td>0.07016</td>\n","      <td>0.7260</td>\n","      <td>1.5950</td>\n","      <td>5.772</td>\n","      <td>86.22</td>\n","      <td>0.006522</td>\n","      <td>0.06158</td>\n","      <td>0.07117</td>\n","      <td>0.01664</td>\n","      <td>0.02324</td>\n","      <td>0.006185</td>\n","      <td>25.740</td>\n","      <td>39.42</td>\n","      <td>184.60</td>\n","      <td>1821.0</td>\n","      <td>0.16500</td>\n","      <td>0.86810</td>\n","      <td>0.9387</td>\n","      <td>0.2650</td>\n","      <td>0.4087</td>\n","      <td>0.12400</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>7.76</td>\n","      <td>24.54</td>\n","      <td>47.92</td>\n","      <td>181.0</td>\n","      <td>0.05263</td>\n","      <td>0.04362</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.1587</td>\n","      <td>0.05884</td>\n","      <td>0.3857</td>\n","      <td>1.4280</td>\n","      <td>2.548</td>\n","      <td>19.15</td>\n","      <td>0.007189</td>\n","      <td>0.00466</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.02676</td>\n","      <td>0.002783</td>\n","      <td>9.456</td>\n","      <td>30.37</td>\n","      <td>59.16</td>\n","      <td>268.6</td>\n","      <td>0.08996</td>\n","      <td>0.06444</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.2871</td>\n","      <td>0.07039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 30 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-506415a5-daee-4058-b6d4-315a10cee594')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-506415a5-daee-4058-b6d4-315a10cee594 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-506415a5-daee-4058-b6d4-315a10cee594');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n","0          17.99         10.38  ...          0.4601                  0.11890\n","1          20.57         17.77  ...          0.2750                  0.08902\n","2          19.69         21.25  ...          0.3613                  0.08758\n","3          11.42         20.38  ...          0.6638                  0.17300\n","4          20.29         14.34  ...          0.2364                  0.07678\n","..           ...           ...  ...             ...                      ...\n","564        21.56         22.39  ...          0.2060                  0.07115\n","565        20.13         28.25  ...          0.2572                  0.06637\n","566        16.60         28.08  ...          0.2218                  0.07820\n","567        20.60         29.33  ...          0.4087                  0.12400\n","568         7.76         24.54  ...          0.2871                  0.07039\n","\n","[569 rows x 30 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","cancer_df = pd.DataFrame(data=cancer.data, columns=cancer_feature_names)\n","cancer_df"]},{"cell_type":"markdown","metadata":{"id":"B4Ulh56A_DVE"},"source":["(4) train, test 데이터 분리\n","\n","모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n","X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요."]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1641741969789,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"CX5OcSZ0Gf_7"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(cancer_data, cancer_label, test_size=0.3, random_state=20)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1641741969790,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"dH8maRQW-w8C","outputId":"a91c1efd-e165-4196-f643-0ee180d13b52"},"outputs":[{"name":"stdout","output_type":"stream","text":["(398, 30) (398,)\n","(171, 30) (171,)\n"]}],"source":["print(x_train.shape, y_train.shape)\n","print(x_test.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"WjdJpT25Geyq"},"source":["(5) 다양한 모델로 학습시켜보기\n","학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n","\n","- Decision Tree 사용해 보기\n","- Random Forest 사용해 보기\n","- SVM 사용해 보기\n","- SGD Classifier 사용해 보기\n","- Logistic Regression 사용해 보기"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1641741969791,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"FKhWHxQI-7i6","outputId":"72bd3793-6080-4b62-fd7c-328eaaba7084"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","DecisionTreeClassifier 분류 모델이다.\n","\n","\n","정답률 : 0.9181286549707602\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.97      0.90        64\n","           1       0.98      0.89      0.93       107\n","\n","    accuracy                           0.92       171\n","   macro avg       0.91      0.93      0.91       171\n","weighted avg       0.93      0.92      0.92       171\n","\n"]}],"source":["# Decision Tree\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","decision_tree = DecisionTreeClassifier(random_state=20)\n","print(decision_tree._estimator_type)\n","print('DecisionTreeClassifier 분류 모델이다.')\n","\n","# 모델 학습\n","decision_tree.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_decision = decision_tree.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_decision))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_decision))"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1641741969792,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"gbrxEkPf_JGt","outputId":"e0f5df13-23c2-4e47-c3ca-9a61a6855990"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","RandomForestClassifier 분류 모델이다.\n","\n","\n","정답률 : 0.9532163742690059\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.97      0.94        64\n","           1       0.98      0.94      0.96       107\n","\n","    accuracy                           0.95       171\n","   macro avg       0.95      0.96      0.95       171\n","weighted avg       0.95      0.95      0.95       171\n","\n"]}],"source":["# Random Forest\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","random_forest = RandomForestClassifier(random_state=20)\n","print(random_forest._estimator_type)\n","print('RandomForestClassifier 분류 모델이다.')\n","\n","# 모델 학습\n","random_forest.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_random = random_forest.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_random))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_random))"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1641741969793,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"iQV7PphD_P7T","outputId":"ac1f81df-0c81-4b83-abe2-315052bff6af"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","Support Vector Machine 분류 모델이다.\n","\n","\n","정답률 : 0.9239766081871345\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.84      0.89        64\n","           1       0.91      0.97      0.94       107\n","\n","    accuracy                           0.92       171\n","   macro avg       0.93      0.91      0.92       171\n","weighted avg       0.93      0.92      0.92       171\n","\n"]}],"source":["# 서포트 벡터 머신(SVM, Support Vector Machine)\n","\n","import sklearn.svm as svm\n","\n","svm = svm.SVC()\n","print(svm._estimator_type)\n","print('Support Vector Machine 분류 모델이다.')\n","\n","# 모델 학습\n","svm.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_svm = svm.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_svm))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_svm))"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1641741969794,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"A-ASZa10_VUc","outputId":"01ff36d4-a76a-4441-9cbc-e6670712d101"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","Stochastic Gradient Descent 분류 모델이다.\n","\n","\n","정답률 : 0.9239766081871345\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.88      0.90        64\n","           1       0.93      0.95      0.94       107\n","\n","    accuracy                           0.92       171\n","   macro avg       0.92      0.91      0.92       171\n","weighted avg       0.92      0.92      0.92       171\n","\n"]}],"source":["# 확률적 경사 하강법 (SGD, Stochastic Gradient Descent)\n","\n","from sklearn.linear_model import SGDClassifier\n","\n","sgd = SGDClassifier()\n","print(sgd._estimator_type)\n","print('Stochastic Gradient Descent 분류 모델이다.')\n","\n","# 모델 학습\n","sgd.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_sgd = sgd.predict(x_test)\n","\n","# 정확도\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_sgd))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_sgd))"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518,"status":"ok","timestamp":1641741970876,"user":{"displayName":"김선아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00416077006155103880"},"user_tz":-540},"id":"q3MwPo92_Yae","outputId":"14283c23-17fd-4cc8-ecf5-2b9b1c742d2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["classifier\n","LogisticRegression 분류 모델이다.\n","\n","\n","정답률 : 0.9473684210526315\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.94      0.93        64\n","           1       0.96      0.95      0.96       107\n","\n","    accuracy                           0.95       171\n","   macro avg       0.94      0.95      0.94       171\n","weighted avg       0.95      0.95      0.95       171\n","\n"]}],"source":["# Logistic Regression\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","logistic = LogisticRegression(max_iter=7000)\n","print(logistic._estimator_type)\n","print('LogisticRegression 분류 모델이다.')\n","\n","# 모델 학습\n","logistic.fit(x_train, y_train)\n","\n","# 예측하기\n","y_pred_logistic = logistic.predict(x_test)\n","\n","# 정확도\n","from sklearn.metrics import accuracy_score\n","print('\\n')\n","print('정답률 :', accuracy_score(y_test, y_pred_logistic))\n","\n","# 레포트\n","print('\\n')\n","print(classification_report(y_test, y_pred_logistic))"]},{"cell_type":"markdown","metadata":{"id":"L3rYlTs27gHT"},"source":["(6) 모델을 평가해 보기\n","\n","학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sKTo4r10TUmd"},"source":["**My Answer** : \n","\n","유방암의 경우, 악성일 경우를 틀리지 않게 예측하는 것이 가장 중요하다고 생각해서, 라벨 0의 리콜 값을 평가지표로 삼았다.\n","Decision Tree와 Random Forest에서 라벨 0의 리콜 값이 0.97으로 같았으나, 라벨 0의 precision과 f1-score 그리고 전체 accuracy 모두를 비교해 보았을 때 조금 더 높게 나온 Random Forest 모델이 더 적합하다고 판단했다.\n","\n","<u>***Random Forest(label 0의 recall) : 0.97***</u>"]},{"cell_type":"markdown","metadata":{"id":"3JY8UFkoTLNp"},"source":["# 회고"]},{"cell_type":"markdown","metadata":{"id":"8371eONcEisG"},"source":["- 이번 프로젝트에서 **어려웠던 점,**\n","\n","    아무래도 평가 지표를 보는 법이 가장 어려웠다.\n","    평가지표들 중에서도 데이터의 특성에 따라서 어떤 것을 기준으로 삼아야 하는지가 중요한데, 그 기준을 올바로 정하기 위해서는 데이터의 내용에 대해서도 잘 알아야하며 데이터를 분류하는 목적에 대해서도 생각해 보아야 했다.\n","    그리고 평가 지표들에 대해서는 익숙하지 않아서 인지 자꾸 개념이 헷갈려서 혼자 빈 종이에 메모를 해 놓으면서 보는 등 개념이 헷갈렸다.\n"]},{"cell_type":"markdown","metadata":{"id":"Yjn4v0D_ElSh"},"source":["- 프로젝트를 진행하면서 **알아낸 점** 혹은 **아직 모호한 점**.\n","\n","    f1-score에 대해서 가장 헷갈렸는데, f1-score는 recall과 precision의 조화평균이라고 적혀있었지만 이해하기가 어려웠다. 조화평균이 무엇인지도 잘 몰랐을 뿐더러, 각 수의 역수들을 산술평균 낸 값이라는 정의를 보았지만 어디에서 어떻게 사용하려고 조화평균을 내는 것인지를 이해하지 못해서 답답했다.\n","    마침 같이 스터디를 하고 있었던 혜령님이 마치 대표값을 설정할 때 이상치가 있으면 단순 산술평균을 사용하지 않고 중앙값을 사용하는 것 처럼, 조화평균도 그런 이상치에 대한 오류를 잡을 수 있는 평균이라고 설명해 주셔서 이해하게 되었다. \n","    https://eunsukimme.github.io/ml/2019/10/21/Accuracy-Recall-Precision-F1-score/\n","    이 블로그를 참고하기도 하였다. 이 블로그에서의 내용도, 혜령님이 말씀해주신 이상치가 있는 경우 단순 산술평균이 대표성을 띠기 어렵다는 내용이었다.\n","\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"vwKhaBtLEnQ_"},"source":["- 루브릭 평가 지표를 맞추기 위해 **시도한 것들**.\n","\n","    - 데이터셋의 구성을 잘 하기 위해 먼저 dir함수를 통해, 각 데이터셋 안에 어떤 메서드나 변수가 들어있는지 확인하였다. 이후 그 메서드에서 feature와 target(label)에 대한 내용을 확인하였고, train 데이터와 test 데이터를 분리시키고 난 뒤에도 shape()메서드를 통해서 입력데이터(x)값이 제대로 2차원 행렬인지, 정답값이 되는 y데이터도 1차원인지 확인을 한 뒤 fit을 시켰다.\n","\n","    - 5가지 모델을 각각 임포트해서 적용하였다.\n","\n","    - 나름의 이유로 평가지표를 설정했고, 꼼꼼히 비교하였다. (각 프로젝트 (6) 모델을 평가해 보기에 상세내용 기술)"]},{"cell_type":"markdown","metadata":{"id":"PHn5VubxEpTa"},"source":["- 만약에 루브릭 평가 관련 지표를 **달성 하지 못했을 때, 이유에 관한 추정**.\n","\n","    각 모델의 평가지표를 잘못 선정했을지도 모른다..."]},{"cell_type":"markdown","metadata":{"id":"8zAmoqpZEqts"},"source":["- **자기 다짐**\n","\n","    평가지표를 각 데이터에 맞게 정하는 것이 가장 힘들고 어려운 작업이었다. 코딩을 잘 하는 것도 중요하지만, 데이터를 잘 이해하고 데이터의 목적에 맞는 지표를 잘 선정하는 게 무엇보다도 중요한 일이라는 것을 느꼈다.\n","    앞으로 많은 데이터와 각 데이터의 선정 지표들을 많이 접하면서, 그냥 지표가 이렇게 나왔으니 이런 결과를 도출했다는 결론만 읽지 말고 왜 그 지표를 대표로 선정했는지를 유심히 관찰해 보아야겠다는 생각이 많이 들었다!"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMZ3jhjcHfQE8h4PsnYDzvG","collapsed_sections":[],"name":"[E-02]load_digits_wine_breast_cancer.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
